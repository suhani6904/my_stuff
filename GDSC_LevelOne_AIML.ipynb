{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhani6904/my_stuff/blob/main/GDSC_LevelOne_AIML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GDSC - Artificial Intelligence & Machine Learning\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **I. Introduction to AI / ML**\n",
        "Machine learning aims to teach a machine how to perform a specific task and provide accurate results by identifying patterns. Curious how ML does this? There's a lot of math and logic that goes behind what's happening in a Machine Learning model.\n",
        "\n",
        "### **II. Supervised & Unsupervised Machine Learning**\n",
        "Supervised learning is the types of machine learning in which machines are trained using well \"labelled\" training data, and on basis of that data, machines predict the output. The labelled data means some input data is already tagged with the correct output.\n",
        "\n",
        "Supervised learning is a process of providing input data as well as correct output data to the machine learning model. The aim of a supervised learning algorithm is to find a mapping function to map the input variable(x) with the output variable(y).\n",
        "\n",
        "Unsupervised learning, also known as unsupervised machine learning, uses machine learning algorithms to analyze and cluster unlabeled datasets. These algorithms discover hidden patterns or data groupings without the need for human intervention.\n",
        "\n",
        "### **III. Level One**\n",
        "For level one, we would be expecting you to research on your own and complete this assignment. We will not be directly explaining the concepts and you would be expected to try to learn it on your own, however, if you do have any doubts regarding this, you can contact Dhruv Shah or Advik Raj Basani. We would be dealing with ONLY Supervised Machine Learning this assignment, and the math involved in this has already been covered either in first year / 12th grade. Math concepts we would expect you to know before you go into this assignment is:\n",
        "\n",
        "*   Multiplication of Matrices\n",
        "*   Dot Product & Cross Product\n",
        "\n",
        "We would also need to know the very basics of Python. This is not a very difficult task and you can familiarise yourself with how Python works with this link: https://www.w3schools.com/python/\n",
        "\n",
        "### **IV. How to Start**\n",
        "First off, go to File -> Save a copy on Drive, and share the new copied file on YOUR drive (with Editing permissions) and fill out this form with the copied share link.\n",
        "\n",
        "https://forms.gle/D6qigSNLEaPf3kTB6\n",
        "\n",
        "And... you're done! You can now get started and learn how ML works.\n",
        "\n"
      ],
      "metadata": {
        "id": "5TnWQuVzylfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1: Linear Regression using Gradient Descent\n",
        "\n",
        "Hey! Welcome to your first assignment question. Let's introduce you to the question.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "You are given a dataset about House Prices in an area. In this dataset, you will have multiple features about the house. You are expected to create a Linear Regression ML model (**ONLY USING NUMPY** - a python library) to predict prices. Below you will find two links - one containing the training dataset and the other containing the test dataset. Your assignment is to fill in the blanks of code and maximize accuracy / minimize loss by using as many features as you can use.\n",
        "\n",
        "Data & Information_about_Features can be found in this drive link: https://drive.google.com/drive/folders/1jTnYiFaUn0czGEmOS637SWgwaNdSDp07?usp=sharing\n",
        "\n",
        "Resources to study:\n",
        "* https://www.geeksforgeeks.org/ml-linear-regression/\n",
        "* https://www.javatpoint.com/cost-function-in-machine-learning\n",
        "* https://www.javatpoint.com/gradient-descent-in-machine-learning\n",
        "* https://www.scaler.com/topics/np-vectorize/\n",
        "* https://www.simplilearn.com/what-is-multiple-linear-regression-in-machine-learning-article\n",
        "* https://www.javatpoint.com/feature-engineering-for-machine-learning\n"
      ],
      "metadata": {
        "id": "nGsmABrIfdeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You want to import the most important libraries here. More specifically, we want you to use ONLY numpy and pandas.\n",
        "\n",
        "import _____ as np\n",
        "import _____ as pd"
      ],
      "metadata": {
        "id": "-IWt8Usxfk7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Functions - You can modify these to your need.\n",
        "def ConvertToInputOutput(dataframe):\n",
        "  Y = dataframe[['SalePrice']]\n",
        "  chosen_feats = [None] #Add the features you think are needed\n",
        "  X = dataframe[chosen_feats]\n",
        "  return X,Y\n",
        "\n",
        "# Normalization Function\n",
        "def Normalize(X):\n",
        "  return (X - X.mean())/(X.std()+0.001)\n",
        "\n",
        "# Randomize a dataset\n",
        "def randomize_dataset(dataset):\n",
        "    dataset = dataset.sample(frac=1)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "IchLUyDhyex3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do note that to run this cell, you need to upload the train.csv and test.csv on the connected runtime's storage.\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "# Use this cell to debug and try to figure out what's happening in the datasets."
      ],
      "metadata": {
        "id": "OaV3NetxgcNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomize your Dataset! Understand why, you should know this.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = ___________________________\n",
        "X, Y = ConvertToInputOutput(train)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = _______)\n",
        "\n",
        "# Preprocessing - You need to be sure of what datatype your X_train and Y_train is. Normalize and figure this out on your own!\n",
        "# There is much much more you can add here. You can modify even string data into numerical data to make the model more accurate in nature.\n",
        "print(\"[PREPROCESSING] Completed\")"
      ],
      "metadata": {
        "id": "_UC9mffNe1d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Okay, to start Linear Regression, you need to have a great grasp on how shapes of matrixs and dimensions work. We expect you to write down on pen and paper how (w, b) works and how (dw, db) would\n",
        "# work in correlation. Implement this in this class.\n",
        "\n",
        "class LinearRegression():\n",
        "  def __init__(self):\n",
        "    self.loss = []\n",
        "\n",
        "  def fit(self,X,Y,learningRate = 0.1,numIterations=10):\n",
        "    m,n = X.shape\n",
        "    self.outputstd = Y.std()\n",
        "    self.outputmean = Y.mean()\n",
        "    self.weights = np.ones('Add your dimensions here!')\n",
        "    self.bias = np.zeros('Add your dimensions here!')\n",
        "\n",
        "    for i  in range(numIterations):\n",
        "      predY = ________________________\n",
        "      error = ___________________\n",
        "      mse = np.square(error).mean()\n",
        "\n",
        "      self.loss.append(mse)\n",
        "\n",
        "      dw = -(1/m)*np.dot(______________)\n",
        "      db = -(1/m)*np.nansum(______________,keepdims = True)\n",
        "      self.weights = self.weights - learningRate*dw\n",
        "      self.bias = self.bias - learningRate*db\n",
        "      if(i%10==0):\n",
        "        print(\"Iteration \", i + 1 ,\"/\",numIterations, \"MSE: \", mse)\n",
        "\n",
        "    print(self.loss)\n",
        "\n",
        "# You need to predict this. Make sure to \"unnormalize\" the prediction cost prices.\n",
        "  def predict(self, X):\n",
        "    return (np.dot(__________) + _________________) * (self.outputstd + 0.001) + self.outputmean\n",
        "\n",
        "  def test(self,X,Y):\n",
        "    predY = __________________________\n",
        "    error = ____________\n",
        "    mse = np.square(error).mean()\n",
        "    print(mse)"
      ],
      "metadata": {
        "id": "v0IAeP6QoS92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LR class here and then fit this with the training data.\n",
        "linear = ___________________________\n",
        "linear.fit(__________________________________________________)"
      ],
      "metadata": {
        "id": "wOVR5yuHraWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, test with the test data.\n",
        "linear.test(_______,  ____________)"
      ],
      "metadata": {
        "id": "qaYXWbh4tLnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2: Logistic Regression\n",
        "Welcome to your second question! Let us introduce you to the question.\n",
        "\n",
        "\n",
        "---\n",
        "You are provided a dataset which is used to predict if a patient has Breast Cancer or not. Your mission, should you choose to accept it, is to use the dataset to create a Logistic Regression model to predict whether a patient is benign / malignant. Try to obtain the highest accuracy.\n",
        "\n",
        "Dataset: https://drive.google.com/drive/folders/1jTnYiFaUn0czGEmOS637SWgwaNdSDp07?usp=sharing\n",
        "\n",
        "Resources to study:\n",
        "* https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n",
        "* https://www.scaler.com/topics/matplotlib/matplotlib-heatmap/\n",
        "* https://www.geeksforgeeks.org/understanding-logistic-regression/\n",
        "* https://www.analyticsvidhya.com/blog/2021/10/building-an-end-to-end-logistic-regression-model/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1kI29GqlZxNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sigmoid function\n",
        "def sigmoid(z):\n",
        "  return _______________________\n",
        "\n",
        "# Defining X and Y\n",
        "def GetInputOutputLR(dataset):\n",
        "  X = dataset.iloc[:, 0:-1]\n",
        "  Y = dataset.iloc[:, -1:]\n",
        "\n",
        "  return X, Y\n",
        "\n",
        "def obtain_training_test_data(X, Y, n):\n",
        "  # Your function! Learn to use pandas to split training and test data!"
      ],
      "metadata": {
        "id": "1z16LMAVrXYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the blanks! You should be comfortable with numpy & pandas now.\n",
        "dataset = pd.read_csv(_________________________)\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "zMf-6-IN7V3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = GetInputOutputLR(dataset)\n",
        "\n",
        "# This dataset has 2, 4 as Benign & Malignant, so we convert it to 0 and 1.\n",
        "Y = Y.replace({_____________________})\n",
        "X_train, X_test, Y_train, Y_test = obtain_training_test_data(X, Y, 0.3)\n",
        "\n",
        "X_train.shape, Y_train.shape"
      ],
      "metadata": {
        "id": "Z8dwB53c0J51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmaps - What library uses heatmaps in Python?\n",
        "import _____________ as sns\n",
        "heatmap = sns.heatmap(dataset.corr(), vmin=-1, vmax=1, annot=True)\n",
        "heatmap.set_title('Correlation Heatmap');\n",
        "\n",
        "# Learn what a correlation heatmap is, we might ask you about this later on."
      ],
      "metadata": {
        "id": "drnkZc7o1DdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalisation - from Question 1, this cell is entirely yours. Add as many features / normalize and preprocess them to try to obtain maximum accuracy.\n",
        "#Pre-processing"
      ],
      "metadata": {
        "id": "Stohumoh1tLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Refer to Andrew NG's lectures of Logistic Regression to understand what's actually happening in terms of matrixs and weights. You can include bias here if you'd like, but we haven't included it\n",
        "# in this case. More points if you figure out how a bias' dimensions would work and actually implement it here.\n",
        "class LogisticRegression():\n",
        "  def __init__(self, learning_rate = 0.1, max_iterations=100):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.max_iterations = max_iterations\n",
        "    self.loss = []\n",
        "    self.w = []\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    self.w = np.zeros((_____________________), dtype=np.float32)\n",
        "\n",
        "    for iteration in range(_______________________):\n",
        "      dw, cost = self.gradient_cost_eval(self.w, X, Y)\n",
        "      self.w -= (self.learning_rate * dw)\n",
        "      self.loss.append(cost)\n",
        "\n",
        "      if iteration % 10 == 0:\n",
        "        print(\"Iteration \", iteration, \"/\", self.max_iterations, \", Loss: \", cost)\n",
        "\n",
        "# Do learn what (z), H(z) and such generic terms stand for, they are often used in the ML community.\n",
        "  def predict(self, X):\n",
        "    w = self.w\n",
        "    H = _________________\n",
        "\n",
        "# What threshold value should you have to say that the prediction is 1?\n",
        "    Y_pred = np.zeros(______________________)\n",
        "    for i in range(H.shape[1]):\n",
        "      if H[0, i] >= _________:\n",
        "        Y_pred[0,i] = 1\n",
        "      else:\n",
        "        Y_pred[0,i] = 0\n",
        "\n",
        "    return Y_pred\n",
        "\n",
        "  def test(self, X, Y):\n",
        "    Y_pred = self.predict(X)\n",
        "    print(\"Accuracy: \", ____________________________)\n",
        "\n",
        "  def hypo(self, w, X):\n",
        "    return sigmoid(__________________)\n",
        "\n",
        "# Use the binary crossentropy loss function here.\n",
        "  def cost(self, H, Y, num_samples):\n",
        "    return _______________________________________\n",
        "\n",
        "  def gradient_cost_eval(self, w, X, Y):\n",
        "    H = self.hypo(w, X)\n",
        "    cost = self.cost(H, Y, len(Y))\n",
        "\n",
        "    temp = (H - Y)\n",
        "    dw = np.dot(___________) / ______________\n",
        "\n",
        "    return dw, cost\n"
      ],
      "metadata": {
        "id": "LNKQ4-QF2XpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How do you define the Logistic Regression model now?\n",
        "LR = _________________________________\n",
        "LR.fit(________________)"
      ],
      "metadata": {
        "id": "nVr5b7Iz-EuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR.test(______________)"
      ],
      "metadata": {
        "id": "RACSOL8F_VP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submissions\n",
        "\n",
        "---\n",
        "\n",
        "You can submit your final solutions using this link:\n",
        "https://forms.gle/42UcG7dFttEStHyY8\n",
        "\n",
        "Thank you!"
      ],
      "metadata": {
        "id": "yhhIJx01cTGS"
      }
    }
  ]
}